{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import timm\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/kaggle/input/isic-2024-challenge\"\n",
    "train_image_dir = f'{root_dir}/train-image/image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_file_path(image_id):\n",
    "    return f\"{train_image_dir}/{image_id}.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = sorted(glob.glob(f\"{train_image_dir}/*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df = pd.read_csv(f\"{root_dir}/train-metadata.csv\")\n",
    "\n",
    "print(\"df.shape, # of positive cases, # of patients\")\n",
    "print(\"original>\", image_df.shape, image_df.target.sum(), image_df[\"patient_id\"].unique().shape)\n",
    "\n",
    "image_df_postive = image_df[image_df[\"target\"] == 1].reset_index(drop=True)\n",
    "image_df_negative = image_df[image_df[\"target\"] == 0].reset_index(drop=True)\n",
    "\n",
    "image_df = pd.concat([image_df_postive, image_df_negative.iloc[:image_df_postive.shape[0]*20, :]])\n",
    "print(\"filtered>\", image_df.shape, image_df.target.sum(), image_df[\"patient_id\"].unique().shape)\n",
    "\n",
    "image_df['file_path'] = image_df['isic_id'].apply(get_train_file_path)\n",
    "image_df = image_df[ image_df[\"file_path\"].isin(train_images) ].reset_index(drop=True)\n",
    "image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df.shape[0], image_df.target.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedGroupKFold(n_splits=5)\n",
    "\n",
    "for fold, ( _, val_) in enumerate(skf.split(image_df, image_df.target, image_df.patient_id)):\n",
    "      image_df.loc[val_ , \"kfold\"] = int(fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISICDataset_for_Train(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df_positive = df[df[\"target\"] == 1].reset_index()\n",
    "        self.df_negative = df[df[\"target\"] == 0].reset_index()\n",
    "        self.file_names_positive = self.df_positive['file_path'].values\n",
    "        self.file_names_negative = self.df_negative['file_path'].values\n",
    "        self.targets_positive = self.df_positive['target'].values\n",
    "        self.targets_negative = self.df_negative['target'].values\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df_positive) * 2\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if random.random() >= 0.5:\n",
    "            df = self.df_positive\n",
    "            file_names = self.file_names_positive\n",
    "            targets = self.targets_positive\n",
    "        else:\n",
    "            df = self.df_negative\n",
    "            file_names = self.file_names_negative\n",
    "            targets = self.targets_negative\n",
    "        index = index % df.shape[0]\n",
    "        \n",
    "        img_path = file_names[index]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        target = targets[index]\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            'image': img,\n",
    "            'target': target\n",
    "        }\n",
    "\n",
    "    \n",
    "class ISICDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df\n",
    "        self.file_names = df['file_path'].values\n",
    "        self.targets = df['target'].values\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.file_names[index]\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        target = self.targets[index]\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            'image': img,\n",
    "            'target': target\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(384, 384),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Flip(p=0.5),\n",
    "        A.Downscale(p=0.25),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, \n",
    "                           scale_limit=0.15, \n",
    "                           rotate_limit=60, \n",
    "                           p=0.5),\n",
    "        A.HueSaturationValue(\n",
    "                hue_shift_limit=0.2, \n",
    "                sat_shift_limit=0.2, \n",
    "                val_shift_limit=0.2, \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.RandomBrightnessContrast(\n",
    "                brightness_limit=(-0.1,0.1), \n",
    "                contrast_limit=(-0.1, 0.1), \n",
    "                p=0.5\n",
    "            ),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.),\n",
    "    \n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(384, 384),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \\\n",
    "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
    "                ', ' + 'eps=' + str(self.eps) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISICModel(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(ISICModel, self).__init__()\n",
    "        self.model = torchvision.models.efficientnet_b0()\n",
    "        \n",
    "        self.model = nn.Sequential(*list(self.model.children())[:-1])\n",
    "        \n",
    "        in_features = 1280\n",
    "        self.gem_pooling = GeM()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(in_features, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.model(x)\n",
    "        pooled_features = self.gem_pooling(features).flatten(1)\n",
    "        pooled_features = self.dropout(pooled_features)\n",
    "        logits = self.fc(pooled_features)\n",
    "        output = self.sigmoid(logits)\n",
    "        return output\n",
    "\n",
    "model = ISICModel()\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, targets):\n",
    "    return nn.BCELoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary auroc metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Optionally import fbgemm_gpu to enable use of hand fused kernel\n",
    "try:\n",
    "    import fbgemm_gpu.metrics\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    torch.ops.load_library(\"//deeplearning/fbgemm/fbgemm_gpu:metric_ops\")\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def binary_auroc(\n",
    "    input: torch.Tensor,\n",
    "    target: torch.Tensor,\n",
    "    *,\n",
    "    num_tasks: int = 1,\n",
    "    weight: Optional[torch.Tensor] = None,\n",
    "    use_fbgemm: Optional[bool] = False,\n",
    ") -> torch.Tensor:\n",
    "\n",
    "    _binary_auroc_update_input_check(input, target, num_tasks, weight)\n",
    "    return _binary_auroc_compute(input, target, weight, use_fbgemm)\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def _binary_auroc_compute_jit(\n",
    "    input: torch.Tensor,\n",
    "    target: torch.Tensor,\n",
    "    weight: Optional[torch.Tensor] = None,\n",
    ") -> torch.Tensor:\n",
    "    threshold, indices = input.sort(descending=True)\n",
    "    mask = F.pad(threshold.diff(dim=-1) != 0, [0, 1], value=1.0)\n",
    "    sorted_target = torch.gather(target, -1, indices)\n",
    "    sorted_weight = (\n",
    "        torch.tensor(1.0, device=target.device)\n",
    "        if weight is None\n",
    "        else torch.gather(weight, -1, indices)\n",
    "    )\n",
    "    cum_tp_before_pad = (sorted_weight * sorted_target).cumsum(-1)\n",
    "    cum_fp_before_pad = (sorted_weight * (1 - sorted_target)).cumsum(-1)\n",
    "\n",
    "    shifted_mask = mask.sum(-1, keepdim=True) >= torch.arange(\n",
    "        mask.size(-1), 0, -1, device=target.device\n",
    "    )\n",
    "\n",
    "    cum_tp = torch.zeros_like(cum_tp_before_pad)\n",
    "    cum_fp = torch.zeros_like(cum_fp_before_pad)\n",
    "\n",
    "    cum_tp.masked_scatter_(shifted_mask, cum_tp_before_pad[mask])\n",
    "    cum_fp.masked_scatter_(shifted_mask, cum_fp_before_pad[mask])\n",
    "\n",
    "    if len(mask.shape) > 1:\n",
    "        factor = cum_tp[:, -1] * cum_fp[:, -1]\n",
    "    else:\n",
    "        factor = cum_tp[-1] * cum_fp[-1]\n",
    "    # Set AUROC to 0.5 when the target contains all ones or all zeros.\n",
    "    auroc = torch.where(\n",
    "        factor == 0,\n",
    "        0.5,\n",
    "        torch.trapz(cum_tp, cum_fp).double() / factor,\n",
    "    )\n",
    "    return auroc\n",
    "\n",
    "\n",
    "def _binary_auroc_compute(\n",
    "    input: torch.Tensor,\n",
    "    target: torch.Tensor,\n",
    "    weight: Optional[torch.Tensor] = None,\n",
    "    use_fbgemm: Optional[bool] = False,\n",
    ") -> torch.Tensor:\n",
    "    if use_fbgemm:\n",
    "        assert input.is_cuda and target.is_cuda, \"Tensors have to be on GPU\"\n",
    "        # auroc does not have weight\n",
    "        weight = torch.ones_like(input, dtype=torch.double)\n",
    "        num_tasks = 1 if len(input.shape) == 1 else input.shape[0]\n",
    "        # FBGEMM AUC is an approximation of AUC. It does not mask data in case\n",
    "        # that input values are redundant. For the highly redundant input case,\n",
    "        # FBGEMM AUC can give a significantly different result\n",
    "        auroc = fbgemm_gpu.metrics.auc(num_tasks, input, target, weight)\n",
    "        if num_tasks == 1:\n",
    "            return auroc[0]\n",
    "        else:\n",
    "            return auroc\n",
    "    else:\n",
    "        return _binary_auroc_compute_jit(input, target, weight)\n",
    "\n",
    "\n",
    "def _binary_auroc_update_input_check(\n",
    "    input: torch.Tensor,\n",
    "    target: torch.Tensor,\n",
    "    num_tasks: int,\n",
    "    weight: Optional[torch.Tensor] = None,\n",
    ") -> None:\n",
    "    if input.shape != target.shape:\n",
    "        raise ValueError(\n",
    "            \"The `input` and `target` should have the same shape, \"\n",
    "            f\"got shapes {input.shape} and {target.shape}.\"\n",
    "        )\n",
    "    if weight is not None and weight.shape != target.shape:\n",
    "        raise ValueError(\n",
    "            \"The `weight` and `target` should have the same shape, \"\n",
    "            f\"got shapes {weight.shape} and {target.shape}.\"\n",
    "        )\n",
    "\n",
    "    if num_tasks == 1:\n",
    "        if len(input.shape) > 1:\n",
    "            raise ValueError(\n",
    "                f\"`num_tasks = 1`, `input` is expected to be one-dimensional tensor, but got shape ({input.shape}).\"\n",
    "            )\n",
    "    elif len(input.shape) == 1 or input.shape[0] != num_tasks:\n",
    "        raise ValueError(\n",
    "            f\"`num_tasks = {num_tasks}`, `input`'s shape is expected to be ({num_tasks}, num_samples), but got shape ({input.shape}).\"\n",
    "        )\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def _multiclass_auroc_compute(\n",
    "    input: torch.Tensor,\n",
    "    target: torch.Tensor,\n",
    "    num_classes: int,\n",
    "    average: Optional[str] = \"macro\",\n",
    ") -> torch.Tensor:\n",
    "    thresholds, indices = input.T.sort(dim=1, descending=True)\n",
    "    mask = F.pad(thresholds.diff(dim=1) != 0, [0, 1], value=1.0)\n",
    "    shifted_mask = mask.sum(-1, keepdim=True) >= torch.arange(\n",
    "        mask.size(-1), 0, -1, device=target.device\n",
    "    )\n",
    "\n",
    "    arange = torch.arange(num_classes, device=target.device)\n",
    "    cmp = target[indices] == arange[:, None]\n",
    "    cum_tp_before_pad = cmp.cumsum(1)\n",
    "    cum_fp_before_pad = (~cmp).cumsum(1)\n",
    "\n",
    "    cum_tp = torch.zeros_like(cum_tp_before_pad)\n",
    "    cum_fp = torch.zeros_like(cum_fp_before_pad)\n",
    "    cum_tp.masked_scatter_(shifted_mask, cum_tp_before_pad[mask])\n",
    "    cum_fp.masked_scatter_(shifted_mask, cum_fp_before_pad[mask])\n",
    "\n",
    "    factor = cum_tp[:, -1] * cum_fp[:, -1]\n",
    "    auroc = torch.where(\n",
    "        factor == 0, 0.5, torch.trapezoid(cum_tp, cum_fp, dim=1) / factor\n",
    "    )\n",
    "    if isinstance(average, str) and average == \"macro\":\n",
    "        return auroc.mean()\n",
    "    return auroc\n",
    "\n",
    "\n",
    "def _multiclass_auroc_param_check(\n",
    "    num_classes: int,\n",
    "    average: Optional[str],\n",
    ") -> None:\n",
    "    average_options = (\"macro\", \"none\", None)\n",
    "    if average not in average_options:\n",
    "        raise ValueError(\n",
    "            f\"`average` was not in the allowed value of {average_options}, got {average}.\"\n",
    "        )\n",
    "    if num_classes < 2:\n",
    "        raise ValueError(\"`num_classes` has to be at least 2.\")\n",
    "\n",
    "\n",
    "def _multiclass_auroc_update_input_check(\n",
    "    input: torch.Tensor,\n",
    "    target: torch.Tensor,\n",
    "    num_classes: int,\n",
    ") -> None:\n",
    "    if input.size(0) != target.size(0):\n",
    "        raise ValueError(\n",
    "            \"The `input` and `target` should have the same first dimension, \"\n",
    "            f\"got shapes {input.shape} and {target.shape}.\"\n",
    "        )\n",
    "\n",
    "    if target.ndim != 1:\n",
    "        raise ValueError(\n",
    "            \"target should be a one-dimensional tensor, \" f\"got shape {target.shape}.\"\n",
    "        )\n",
    "\n",
    "    if not (input.ndim == 2 and input.shape[1] == num_classes):\n",
    "        raise ValueError(\n",
    "            f\"input should have shape of (num_sample, num_classes), \"\n",
    "            f\"got {input.shape} and num_classes={num_classes}.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_auroc  = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:\n",
    "        images = data['image'].to(device, dtype=torch.float)\n",
    "        targets = data['target'].to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        \n",
    "        outputs = model(images).squeeze()\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss = loss / 1\n",
    "            \n",
    "        loss.backward()\n",
    "    \n",
    "        if (step + 1) % 1 == 0:\n",
    "            optimizer.step()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "                \n",
    "        auroc = binary_auroc(input=outputs.squeeze(), target=targets).item()\n",
    "        \n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        running_auroc  += (auroc * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        epoch_auroc = running_auroc / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss, Train_Auroc=epoch_auroc,\n",
    "                        LR=optimizer.param_groups[0]['lr'])\n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, epoch_auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def valid_one_epoch(model, dataloader, device, epoch):\n",
    "    model.eval()\n",
    "    \n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    running_auroc = 0.0\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n",
    "    for step, data in bar:        \n",
    "        images = data['image'].to(device, dtype=torch.float)\n",
    "        targets = data['target'].to(device, dtype=torch.float)\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        outputs = model(images).squeeze()\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        auroc = binary_auroc(input=outputs.squeeze(), target=targets).item()\n",
    "        running_loss += (loss.item() * batch_size)\n",
    "        running_auroc  += (auroc * batch_size)\n",
    "        dataset_size += batch_size\n",
    "        \n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        epoch_auroc = running_auroc / dataset_size\n",
    "        \n",
    "        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss, Valid_Auroc=epoch_auroc,\n",
    "                        LR=optimizer.param_groups[0]['lr'])   \n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    return epoch_loss, epoch_auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(model, optimizer, scheduler, device, num_epochs):\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n",
    "    \n",
    "    start = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_epoch_auroc = -np.inf\n",
    "    history = defaultdict(list)\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1): \n",
    "        gc.collect()\n",
    "        train_epoch_loss, train_epoch_auroc = train_one_epoch(model, optimizer, scheduler, \n",
    "                                           dataloader=train_loader, \n",
    "                                           device='cuda', epoch=epoch)\n",
    "        \n",
    "        val_epoch_loss, val_epoch_auroc = valid_one_epoch(model, valid_loader, device='cuda', \n",
    "                                         epoch=epoch)\n",
    "    \n",
    "        history['Train Loss'].append(train_epoch_loss)\n",
    "        history['Valid Loss'].append(val_epoch_loss)\n",
    "        history['Train AUROC'].append(train_epoch_auroc)\n",
    "        history['Valid AUROC'].append(val_epoch_auroc)\n",
    "        history['lr'].append( scheduler.get_lr()[0] )\n",
    "        \n",
    "        # deep copy the model\n",
    "        if best_epoch_auroc <= val_epoch_auroc:\n",
    "            print(f\"{b_}Validation AUROC Improved ({best_epoch_auroc} ---> {val_epoch_auroc})\")\n",
    "            best_epoch_auroc = val_epoch_auroc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            PATH = \"AUROC{:.4f}_Loss{:.4f}_epoch{:.0f}.bin\".format(val_epoch_auroc, val_epoch_loss, epoch)\n",
    "            torch.save(model.state_dict(), PATH)\n",
    "            # Save a model file from the current directory\n",
    "            print(f\"Model Saved{sr_}\")\n",
    "            \n",
    "        print()\n",
    "    \n",
    "    end = time.time()\n",
    "    time_elapsed = end - start\n",
    "    print('Training complete in {:.0f}h {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "    print(\"Best AUROC: {:.4f}\".format(best_epoch_auroc))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_scheduler(optimizer, name):\n",
    "    if name == 'CosineAnnealingLR':\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(optimizer,T_max=500, \n",
    "                                                   eta_min=1e-6)\n",
    "    elif name == 'CosineAnnealingWarmRestarts':\n",
    "        scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer,T_0=100, \n",
    "                                                             eta_min=1e-6)\n",
    "    elif name == None:\n",
    "        return None\n",
    "        \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_loaders(df, fold):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    train_dataset = ISICDataset_for_Train(df_train, transforms=data_transforms[\"train\"])\n",
    "    valid_dataset = ISICDataset(df_valid, transforms=data_transforms[\"valid\"])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, \n",
    "                              num_workers=2, shuffle=True, pin_memory=True, drop_last=True)\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=64, \n",
    "                              num_workers=2, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = prepare_loaders(image_df, fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, \n",
    "                       weight_decay=1e-6)\n",
    "scheduler = fetch_scheduler(optimizer, 'CosineAnnealingLR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = run_training(model, optimizer, scheduler,\n",
    "                              device='cuda',\n",
    "                              num_epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_csv = f'{root_dir}/test-metadata.csv'\n",
    "test_hdf = f'{root_dir}/test-image.hdf5'\n",
    "sample = f'{root_dir}/sample_submission.csv'\n",
    "\n",
    "best_weight = \"/kaggle/working/AUROC0.5176_Loss0.3409_epoch423.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(test_csv)\n",
    "df['target'] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.read_csv(sample)\n",
    "df_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ISICTestDataset(Dataset):\n",
    "    def __init__(self, df, file_hdf, transforms=None):\n",
    "        self.df = df\n",
    "        self.fp_hdf = h5py.File(file_hdf, mode=\"r\")\n",
    "        self.isic_ids = df['isic_id'].values\n",
    "        self.targets = df['target'].values\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.isic_ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        isic_id = self.isic_ids[index]\n",
    "        img = np.array( Image.open(BytesIO(self.fp_hdf[isic_id][()])) )\n",
    "        target = self.targets[index]\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "            \n",
    "        return {\n",
    "            'image': img,\n",
    "            'target': target,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(384, 384),\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ISICModel()\n",
    "model.load_state_dict( torch.load(best_weight) )\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ISICTestDataset(df, test_hdf, transforms=data_transforms[\"valid\"])\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, \n",
    "                          num_workers=2, shuffle=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    bar = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    for step, data in bar:        \n",
    "        images = data['image'].to('cuda', dtype=torch.float)        \n",
    "        batch_size = images.size(0)\n",
    "        outputs = model(images)\n",
    "        preds.append( outputs.detach().cpu().numpy() )\n",
    "preds = np.concatenate(preds).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub[\"target\"] = preds\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
